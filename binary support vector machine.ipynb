{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm is where we really step into the door of machine learning\n",
    "#i personally think andrew ng did a shitty job in teaching this topic\n",
    "#i strong recommend readers to go to the following website\n",
    "# https://www.svm-tutorial.com/\n",
    "#this site was created by a polish developer called Alexandre Kowalczyk\n",
    "#he dedicated to teach svm from the very basic notation of vectors and lagrangian\n",
    "#very friendly for beginners who forget everything about high school math\n",
    "#and the free e-book he wrote is a must-read for more advanced techniques\n",
    "#such as l1,l2 regularized soft margin, kernel, smo, multiclass classification\n",
    "\n",
    "import cvxopt.solvers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.chdir('d:/python/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the classification has to be float instead of int\n",
    "#this is requested by cvxopt\n",
    "#for a binary classification\n",
    "#the value should be either -1.0 or 1.0\n",
    "df['y']=np.select([df['type']=='Iris-setosa', \\\n",
    "                   df['type']=='Iris-versicolor', \\\n",
    "                   df['type']=='Iris-virginica'],[-1.0,0.0,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the simplicity, let us make it a binary classification\n",
    "df=df[df['y']!=0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the simplicity, let us reduce the dimension of x to 2\n",
    "temp=pd.concat([df[i] for i in df.columns if 'length' in i or 'width' in i],axis=1)\n",
    "x=PCA(n_components=1).fit_transform(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.Series([x[i].item() for i in range(len(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crucial!!!!\n",
    "#or we would get errors in the next step\n",
    "x_test.reset_index(inplace=True,drop=True)\n",
    "y_test.reset_index(inplace=True,drop=True)\n",
    "x_train.reset_index(inplace=True,drop=True)\n",
    "y_train.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm for binary classification\n",
    "def binary_svm(x_train,x_test,y_train,y_test,kernel='linear',poly_constant=0.0,poly_power=1,gamma=5):\n",
    "\n",
    "    #this is outer product matrix\n",
    "    #which is the combination of all inner products\n",
    "    #alternatively,we can write outer product in\n",
    "    #np.mat([np.dot(y_train[i],y_train[j]) for j in y_train.index for i in y_train.index]).reshape(len(y_train),len(y_train))\n",
    "    #or just np.mat(y_train).T*np.mat(y_train)\n",
    "    y_product=np.outer(y_train,y_train)\n",
    "    \n",
    "    #using different kernels to map inner product to a higher dimension space\n",
    "    #there are only three kernels here, which are linear, polynomial, gaussian\n",
    "    if kernel=='linear':\n",
    "        x_product=np.outer(x_train,x_train)\n",
    "    elif kernel=='polynomial':\n",
    "        temp=np.outer(x_train,x_train)\n",
    "        x_product=np.apply_along_axis(lambda x:(x+poly_constant)**poly_power,0,temp.ravel()).reshape(temp.shape)\n",
    "    else:\n",
    "        #gaussian/rbf kernel\n",
    "        #map to infinitive dimension space\n",
    "        temp=np.mat([i-j for j in x_train for i in x_train]).reshape(len(x_train),len(x_train))\n",
    "        x_product=np.apply_along_axis(lambda x:np.exp(-1*gamma*(np.linalg.norm(x))**2),0,temp.ravel()).reshape(temp.shape)\n",
    "    \n",
    "    #plz refer to the following link for how to solve wolfe dual problem in cvxopt\n",
    "    # http://cvxopt.org/userguide/coneprog.html#quadratic-programming\n",
    "    P=cvxopt.matrix(x_product*y_product)\n",
    "    q=cvxopt.matrix(-1*np.ones(len(x_train)))\n",
    "    G=cvxopt.matrix(np.diag(-1 * np.ones(len(x_train))))\n",
    "    h=cvxopt.matrix(np.zeros(len(x_train)))\n",
    "    A=cvxopt.matrix(y_train,(1,len(x_train)))\n",
    "    b=cvxopt.matrix(0.0)\n",
    "\n",
    "    solution=cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "    alpha=pd.Series(solution['x'])\n",
    "    w=np.sum(alpha*y_train*x_train)\n",
    "\n",
    "    #here i am using prof andrew ng's way\n",
    "    #alternatively, we can do a normal average of all value b\n",
    "    #b=np.mean(y_train-w*x_train)\n",
    "    b=-(min(x_train[y_train==1.0]*w)+max(x_train[y_train==-1.0]*w))/2\n",
    "\n",
    "    print('\\ntrain accuracy: %s'%(len(y_train[np.sign(np.multiply(w,x_train)+b)==y_train])/len(y_train)*100)+'%')\n",
    "    print('\\ntest accuracy: %s'%(len(y_test[np.sign(np.multiply(w,x_test)+b)==y_test])/len(y_test)*100)+'%')\n",
    "    print('\\nparameters w: %s'%(w))\n",
    "    print('\\nparameters b: %s'%(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.8386e+00 -8.7437e+00  6e+00  3e-16  1e+00\n",
      " 1: -2.9601e+00 -3.6279e+00  7e-01  2e-16  2e-01\n",
      " 2: -3.0560e+00 -3.1621e+00  1e-01  2e-16  2e-02\n",
      " 3: -3.0967e+00 -3.1123e+00  2e-02  1e-16  1e-16\n",
      " 4: -3.1025e+00 -3.1055e+00  3e-03  2e-16  1e-16\n",
      " 5: -3.1034e+00 -3.1049e+00  1e-03  3e-16  1e-16\n",
      " 6: -3.1041e+00 -3.1044e+00  3e-04  4e-16  1e-16\n",
      " 7: -3.1043e+00 -3.1043e+00  6e-05  4e-16  1e-16\n",
      " 8: -3.1043e+00 -3.1043e+00  8e-06  7e-16  2e-16\n",
      " 9: -3.1043e+00 -3.1043e+00  2e-07  4e-16  2e-16\n",
      "Optimal solution found.\n",
      "\n",
      "train accuracy: 100.0%\n",
      "\n",
      "test accuracy: 100.0%\n",
      "\n",
      "parameters w: 15.124567872650465\n",
      "\n",
      "parameters b: 8.641313505812779\n"
     ]
    }
   ],
   "source": [
    "binary_svm(x_train,x_test,y_train,y_test,kernel='gaussian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using official sklearn package with the same parameters\n",
    "def skl_binary_svm(x_train,x_test,y_train,y_test,kernel='rbf',gamma=5,**kwargs):\n",
    "    \n",
    "    m=SVC(kernel=kernel,gamma=gamma, \\\n",
    "          **kwargs).fit(np.array(x_train).reshape(-1, 1), \\\n",
    "                        np.array(y_train).ravel())\n",
    "    \n",
    "    train=m.score(np.array(x_train).reshape(-1, 1), \\\n",
    "                  np.array(y_train).ravel())*100\n",
    "    test=m.score(np.array(x_test).reshape(-1, 1), \\\n",
    "                 np.array(y_test).ravel())*100\n",
    "    \n",
    "    print('\\ntrain accuracy: %s'%(train)+'%')\n",
    "    print('\\ntest accuracy: %s'%(test)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train accuracy: 100.0%\n",
      "\n",
      "test accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "skl_binary_svm(x_train,x_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
