{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Platt Burges\n",
    "\n",
    "&nbsp;\n",
    "    \n",
    "This script solves Platt-Burges model via regularized least squares with L2 norm penalty (Ridge Regression). Albeit the default solver in our repository is Expectation Maximization algorithm. Certainly there are merits to EM algorithm. \n",
    "\n",
    "1. You have a more detailed derivation from Stanford CS229 Autumn 2016 Problem Set 4 Problem 2. \n",
    "2. EM algorithm can give us the standard deviation of both intrinsic value and bias level whereas RLS only yields the mean of intrinsic value and bias level.\n",
    "3. L2 penalty is implemented on bias level and its coefficient $\\lambda$ is more arbitrary than EM algorithm's tolerance level. Since we are running a complete matrix here, we cannot play around cross validation to compute the optimal $\\lambda$. \n",
    "\n",
    "Despite all the malaises we list out, why are we doing RLS? It is fast and straight forward. Assuming $P$ papers are submitted to the conference and $R$ reviewers in the committee mark the score of these papers, each paper will be given $R$ different scores by all the reviewers. Therefore, the score of a paper given by a reviewer, denoted as $x$, can be decomposed into the linear combination of three components â€“ the underlying intrinsic value $y$, the reviewer bias $z$ and some random disturbance $\\epsilon$. $x$, $y$ and $z$ independently follow different Gaussian distributions.\n",
    "\n",
    "$$ y^{(pr)} \\sim \\mathcal{N} (\\mu_p,\\sigma_p^2)$$\n",
    "\n",
    "$$ z^{(pr)} \\sim \\mathcal{N} (\\nu_r,\\tau_r^2)$$\n",
    "\n",
    "$$ x^{(pr)}|y^{(pr)},z^{(pr)} \\sim \\mathcal{N} (y^{(pr)}+z^{(pr)},\\sigma^2)$$\n",
    "\n",
    "RLS solves Platt-Burges model by minimizing the loss function $\\mathcal{L}$.\n",
    "\n",
    "$$ \\mathcal{L}=\\frac {1}{2} \\sum_{p=1}^P\\sum_{r=1}^R (x^{(pr)}-\\mu_p-\\nu_r)^2+\\frac {1}{2} \\sum_{r=1}^R \\lambda \\nu_r^2$$\n",
    "\n",
    "For EM algorithm, plz check the below\n",
    "\n",
    "https://github.com/je-suis-tm/machine-learning/blob/master/Wisdom%20of%20Crowds%20project/platt%20burges.ipynb\n",
    "\n",
    "Reference to Hong Ge's paper\n",
    "\n",
    "http://mlg.eng.cam.ac.uk/hong/unpublished/nips-review-model.pdf\n",
    "\n",
    "Neil Lawrence's personal blog\n",
    "\n",
    "https://inverseprobability.com/2014/08/02/reviewer-calibration-for-nips\n",
    "\n",
    "Neil Lawrence's jupyter notebook\n",
    "\n",
    "https://github.com/lawrennd/conference\n",
    "\n",
    "Others' jupyter notebook\n",
    "\n",
    "https://github.com/leonidk/reviewers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.chdir('K:/ecole/github/televerser/wisdom of crowds')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#raise error when zero is encountered in logarithm\n",
    "np.seterr(divide='raise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute rls loss function\n",
    "def loss_function(x0,data,lambda_):\n",
    "    \n",
    "    #unpack\n",
    "    intrinsic_value=x0[:data.shape[1]]\n",
    "    bias_level=x0[data.shape[1]:]\n",
    "\n",
    "    #convert intrinsic value and bias lvl into matrix\n",
    "    miu_p=np.repeat(np.array(intrinsic_value).reshape(1,-1),data.shape[0],axis=0)\n",
    "    nu_r=np.repeat(np.array(bias_level).reshape(-1,1),data.shape[1],axis=1)\n",
    "\n",
    "    #compute loss function\n",
    "    rls_loss=np.square(\n",
    "        data-miu_p-nu_r).sum()/2+lambda_*np.square(bias_level).sum()/2\n",
    "    \n",
    "    return rls_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using rls to solve platt burges\n",
    "def regularized_least_square(X,lambda_=0.5,**kwargs):\n",
    "\n",
    "    #pack\n",
    "    miu_init=X.mean(axis=0).ravel().tolist()[0]\n",
    "    nu_init=X.mean(axis=1).ravel().tolist()[0]\n",
    "    x0=miu_init+nu_init\n",
    "\n",
    "    #rls\n",
    "    result=scipy.optimize.minimize(loss_function,x0,\n",
    "                                   args=(X,lambda_),\n",
    "                                   **kwargs\n",
    "                                  )\n",
    "\n",
    "    if result['success']:\n",
    "\n",
    "        #unpack\n",
    "        intrinsic_value=result['x'][:X.shape[1]]\n",
    "        bias_level=result['x'][X.shape[1]:]\n",
    "\n",
    "        return intrinsic_value,bias_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "y0matrix2019=pd.read_csv('y0matrix2019.csv')\n",
    "\n",
    "y1matrix2020=pd.read_csv('y1matrix2020.csv')\n",
    "\n",
    "monthly=pd.read_csv('monthly.csv')\n",
    "\n",
    "annual=pd.read_csv('annual.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set index\n",
    "y0matrix2019.set_index('Source Name',inplace=True)\n",
    "\n",
    "y1matrix2020.set_index('Source Name',inplace=True)\n",
    "\n",
    "monthly.set_index('Date',inplace=True)\n",
    "monthly.index=pd.to_datetime(monthly.index)\n",
    "monthly.columns=y0matrix2019.columns\n",
    "\n",
    "annual=annual.pivot(index='Date',\n",
    "                    columns='Name',values='Value')\n",
    "annual.index=pd.to_datetime(annual.index)\n",
    "annual.columns=y0matrix2019.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize forecast by pct return\n",
    "y0_mat_nor=np.mat(\n",
    "    np.divide(y0matrix2019,\n",
    "              monthly['2019-08-31':'2019-08-31'])-1)\n",
    "y1_mat_nor=np.mat(\n",
    "    np.divide(y1matrix2020,\n",
    "              monthly['2019-08-31':'2019-08-31'])-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01475545  0.01399294  0.00063756 -0.02127891 -0.00941928  0.0029321\n",
      " -0.01331331  0.01169339]\n",
      "[0.02019064, 0.02024495, 0.00609068, -0.01649482, -0.00426001, 0.00847965, -0.00821187, 0.01734934]\n"
     ]
    }
   ],
   "source": [
    "#current year outlook\n",
    "intrinsic_value,bias_level=regularized_least_square(y0_mat_nor,lambda_=0.5,)\n",
    "\n",
    "print(bias_level)\n",
    "\n",
    "#comparison with result from em\n",
    "print([0.02019064,0.02024495,0.00609068,-0.01649482,-0.00426001,\n",
    "0.00847965,-0.00821187,0.01734934])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00299608  0.01043045 -0.00037993 -0.02092039 -0.02842805 -0.02943199\n",
      " -0.03099745  0.10272337]\n",
      "[0.01352132, 0.02981012, 0.01582776, -0.00265233, -0.01151194, -0.01075301, -0.01477036, 0.12330401]\n"
     ]
    }
   ],
   "source": [
    "#one year ahead outlook\n",
    "intrinsic_value,bias_level=regularized_least_square(y1_mat_nor,lambda_=0.5,)\n",
    "\n",
    "print(bias_level)\n",
    "\n",
    "#comparison with result from em\n",
    "print([0.01352132,0.02981012,0.01582776,-0.00265233,-0.01151194,\n",
    "-0.01075301,-0.01477036,0.12330401])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "154px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
