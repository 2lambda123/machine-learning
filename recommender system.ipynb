{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommender System\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Recommender system is a system widely used in Amazon, Netflix to predict user rating for a given item. Usually the system involves collaborative filtering, content-based filtering, session-based filtering or even a mixture.\n",
    "\n",
    "* Collaborative filtering seeks connections across different users and items to predict the rating. It is more related to unsupervised learning. Even inside collaborative filtering, there are a few different techniques such as model-based (matrix factorization, latent variables), memory-based (neighborhood correlation model, KNN) and even a hybrid of both. Collaborative filtering will be the main focus of this script. \n",
    "* Content-based filtering collects user and item profile. Based upon the features in the profile, it forecasts the user preference towards different items. It is more related to supervised learning.\n",
    "* Session-based filtering monitors the user interaction within a session to create recommendations. It is quite helpful to navigate through the cold start problem where a new user has not much available information for modelling. It is more related to deep learning, in particular, Recurrent Neural Network.\n",
    "\n",
    "In a recommender system, not every customer rates every item so it effectively forms a partially filled customer vs item matrix. To recommend anything to the existing customer, a fully filled matrix must be inferred from the dataset. This falls into the spectrum of matrix completion. The most popular sub-problem of matrix completion is to find a low rank matrix via convex optimization (Cand√®s and Recht, 2008). The sub-problem assumes there must be latent variables influencing the users and the items in the matrix. Thus, the matrix must be low rank.\n",
    "\n",
    "Reference to matrix completion\n",
    "\n",
    "https://github.com/je-suis-tm/machine-learning/blob/master/matrix%20completion.ipynb\n",
    "\n",
    "Reference to KNN\n",
    "\n",
    "https://github.com/je-suis-tm/machine-learning/blob/master/k%20nearest%20neighbors.ipynb\n",
    "\n",
    "Reference to every model in this script\n",
    "\n",
    "https://people.engr.tamu.edu/huangrh/Spring16/papers_course/matrix_factorization.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('K:/ecole/github/televerser/matrix completion')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data comes from the link below\n",
    "# http://files.grouplens.org/datasets/movielens/ml-100k/u.data\n",
    "df=pd.read_csv('movielens.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert array into matrix form\n",
    "matrix=df.pivot(index='item',columns='user',values='rating')\n",
    "arr=np.array(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funk SVD\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Simon Funk developed a SVD-like latent factor model to win 3rd prize in 2006 Netflix problem. Conventionally people call it Funk SVD, although it is merely inspired by Singular Value Decomposition without explicitly using SVD. Funk SVD is really easy to implement and quick to converge with high accuracy. It is a type of collaborative filtering focusing on matrix factorization. The official optimization problem is formulated as below.\n",
    "\n",
    "$$ \\min_{p_*,q_*,b_*}\\,\\sum_{r_{ui}\\,\\in\\,\\mathcal{K}} \\left(r_{ui} - \\hat{r}_{ui} \\right)^2 + \\lambda( ||p_u||^2 + ||q_i||^2 + b_u^2 + b_i^2 )$$\n",
    "\n",
    "where \n",
    "\n",
    "${r}_{ui}$ denotes the rating of item $i$ by user $u$\n",
    "\n",
    "$\\hat{r}_{ui}$ denotes the estimated rating of item $i$ by user $u$, it can be decomposed into the form of $\\mu + b_u + b_i + p_u^Tq_i$\n",
    "\n",
    "$\\mathcal{K}$ denotes the observed user vs item matrix (partially filled)\n",
    "\n",
    "$\\mu$ denotes overall average rating\n",
    "\n",
    "$b_u$ denotes the deviation from overall average rating caused by user $u$, \n",
    "\n",
    "$b_i$ denotes the deviation from overall average rating caused by item $i$\n",
    "\n",
    "$p_u$ denotes the latent factors of user $u$, in translation, user preference\n",
    "\n",
    "$q_i$ denotes the latent factors of item $i$, in translation, item attributes\n",
    "\n",
    "$\\lambda$ denotes LaGrange multiplier which is the coefficient of L2 penalty function\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "To explain a bit, Funk SVD assumes that both user and item are affected by $N$ number of latent factors ($p_u \\in \\mathbb{R}^{N}\\,\\&\\,q_i \\in \\mathbb{R}^{N}$). These latent factors could be percentage of action in the movie, number of tier 1 hollywood stars, etc. The rating $r_{ui}$ is merely the linear combination $p_u^Tq_i$ of user preference and item attributes. This decomposition is similar to SVD in the form of $U\\Sigma V^T$ without the eigenvalue diagonal $\\Sigma$ as scaling factors. Hence, the first bit of the objective function is an ordinary least square to minimize the sum of squared error between existing rating and estimated rating. Since the matrix is partially filled, the second bit of the objective function is L2 norm regularization on user preference $p_u$, item attributes $q_i$, user deviation $b_u$ and item deviation $b_i$ to avoid overfit problem.\n",
    "\n",
    "The actual optimization solver is inspired by gradient descent $\\theta:=\\theta-\\alpha\\frac{\\partial J(\\theta)}{\\partial \\theta}$. Applying the same logic to every unknown parameters $p_u$, $q_i$, $b_u$ and $b_i$, we end up with the following updates.\n",
    "\n",
    "$$b_u := b_u + \\alpha (\\epsilon_{ui} - \\lambda b_u)$$\n",
    "$$b_i := b_i + \\alpha (\\epsilon_{ui} - \\lambda b_i)$$\n",
    "$$p_u := p_u + \\alpha (\\epsilon_{ui} \\cdot q_i - \\lambda p_u)$$\n",
    "$$q_i := q_i + \\alpha (\\epsilon_{ui} \\cdot p_u - \\lambda q_i)$$\n",
    "\n",
    "where\n",
    "\n",
    "$\\epsilon_{ui}$ denotes the error between existing rating and estimated rating in the form of $r_{ui} - \\hat{r}_{ui}$\n",
    "\n",
    "$\\gamma$ denotes the learning rate of gradient descent which dictates how soon the solver reaches the local optima\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Reference to Singular Value Decomposition\n",
    "\n",
    "https://github.com/je-suis-tm/machine-learning/blob/master/principal%20component%20analysis.ipynb\n",
    "\n",
    "Reference to Gradient Descent\n",
    "\n",
    "https://github.com/je-suis-tm/machine-learning/blob/master/gradient%20descent.ipynb\n",
    "\n",
    "Reference to Simon Funk's blog\n",
    "\n",
    "https://sifter.org/~simon/journal/20061211.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use numba to dramatically boost the speed of linear algebra\n",
    "@njit\n",
    "def funk_svd_epoch(arr,miu,b_u,b_i,p_u,q_i,alpha,lambda_):\n",
    "    \n",
    "    #initialize\n",
    "    error=0\n",
    "    \n",
    "    #only iterate known ratings\n",
    "    for i in range(arr.shape[0]):\n",
    "        for u in range(arr.shape[1]):\n",
    "            r_ui=arr[i,u]\n",
    "            \n",
    "            #another way to identify nan\n",
    "            #r_ui!=r_ui\n",
    "            if np.isnan(r_ui):\n",
    "                continue\n",
    "\n",
    "            #compute error\n",
    "            epsilon_ui=r_ui-miu-b_u[u]-b_i[i]-p_u[u].T@q_i[i]\n",
    "            error+=epsilon_ui\n",
    "\n",
    "            #update\n",
    "            b_u[u]+=alpha*(epsilon_ui-lambda_*b_u[u])\n",
    "            b_i[i]+=alpha*(epsilon_ui-lambda_*b_i[i])\n",
    "            for f in range(p_u.shape[1]):\n",
    "                p_u_f=p_u[u,f]\n",
    "                q_i_f=q_i[i,f]\n",
    "                p_u[u,f]+=alpha*(epsilon_ui*q_i_f-lambda_*p_u_f)\n",
    "                q_i[i,f]+=alpha*(epsilon_ui*p_u_f-lambda_*q_i_f)\n",
    "    \n",
    "    return error,b_u,b_i,p_u,q_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svd inspired latent factor model by simon funk\n",
    "def funk_svd(arr,miu_init=None,b_u_init=None,b_i_init=None,\n",
    "             p_u_init=None,q_i_init=None,num_of_rank=40,\n",
    "             alpha=0.005,lambda_=0.02,tau=0.0001,\n",
    "             max_iter=20,diagnosis=True\n",
    "             ):\n",
    "\n",
    "    #initialize\n",
    "    stop=False\n",
    "    counter=0\n",
    "    sse=None\n",
    "    \n",
    "    #global mean\n",
    "    if not miu_init:       \n",
    "        miu=arr[~np.isnan(arr)].mean()\n",
    "    else:\n",
    "        miu=miu_init\n",
    "        \n",
    "    #user bias\n",
    "    if not b_u_init:\n",
    "        b_u=np.zeros(arr.shape[1])\n",
    "    else:\n",
    "        b_u=b_u_init\n",
    "    \n",
    "    #item bias\n",
    "    if not b_i_init:\n",
    "        b_i=np.zeros(arr.shape[0])\n",
    "    else:\n",
    "        b_i=b_i_init\n",
    "        \n",
    "    #user latent factors\n",
    "    if not p_u_init:\n",
    "        p_u=np.zeros((arr.shape[1],num_of_rank))\n",
    "        p_u.fill(0.1)\n",
    "    else:\n",
    "        p_u=p_u_init\n",
    "    \n",
    "    #item latent factors\n",
    "    if not q_i_init:\n",
    "        q_i=np.zeros((arr.shape[0],num_of_rank))\n",
    "        q_i.fill(0.1)\n",
    "    else:\n",
    "        q_i=q_i_init\n",
    "    \n",
    "    #gradient descent\n",
    "    while not stop:\n",
    "        \n",
    "        error,b_u,b_i,p_u,q_i=funk_svd_epoch(arr,miu,b_u,b_i,p_u,q_i,alpha,lambda_)\n",
    "\n",
    "        counter+=1\n",
    "\n",
    "        #maximum number of epoch\n",
    "        if counter>=max_iter:\n",
    "            stop=True\n",
    "            if diagnosis:\n",
    "                print('Not converged. Consider increase number of iterations or tolerance')\n",
    "                \n",
    "        #use sum of squared error to determine if converged\n",
    "        sse_prev=sse\n",
    "        sse=error**2\n",
    "        if sse_prev and abs(sse/sse_prev-1)<=tau:\n",
    "            stop=True\n",
    "            if diagnosis:\n",
    "                print(f'{counter} iterations to reach convergence\\n')\n",
    "\n",
    "    return b_u,b_i,p_u,q_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize\n",
    "num_of_latent_factors=40\n",
    "max_num_of_epoch=500\n",
    "learning_rate=0.01\n",
    "lagrange_multiplier=0.02\n",
    "tolerance=0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166 iterations to reach convergence\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#funk svd\n",
    "b_u,b_i,p_u,q_i=funk_svd(arr,num_of_rank=num_of_latent_factors,\n",
    "         alpha=learning_rate,\n",
    "         lambda_=lagrange_multiplier,tau=tolerance,\n",
    "         max_iter=max_num_of_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute global mean\n",
    "miu=arr[~np.isnan(arr)].mean()\n",
    "\n",
    "#matrix completion\n",
    "output=miu+np.repeat(\n",
    "            b_u.reshape(1,-1),\n",
    "            arr.shape[0],axis=0)+np.repeat(\n",
    "            b_i.reshape(-1,1),arr.shape[1],axis=1)+q_i@p_u.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funk SVD Mean Squared Error: 0.752\n"
     ]
    }
   ],
   "source": [
    "#use mse as benchmark for comparison\n",
    "mse_funk_svd=np.square((output-arr)[~np.isnan(arr)]).sum()/len(arr[~np.isnan(arr)])\n",
    "print('Funk SVD Mean Squared Error:',round(mse_funk_svd,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "154px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
